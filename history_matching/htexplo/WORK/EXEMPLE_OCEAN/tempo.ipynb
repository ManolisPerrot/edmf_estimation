{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening ../../../../data/FC500/FC500_interpolated_on_SCM.nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running FC500 for SCM-1-002Running FC500 for SCM-1-003Running FC500 for SCM-1-004Running FC500 for SCM-1-001\n",
      "Running FC500 for SCM-1-005\n",
      "\n",
      "\n",
      "Running FC500 for SCM-1-006Running FC500 for SCM-1-007\n",
      "Running FC500 for SCM-1-008\n",
      "\n",
      "\n",
      "Running FC500 for SCM-1-009Running FC500 for SCM-1-010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Imports\n",
    "###########################################\n",
    "import sys  # to put the SCM into the PYTHONPATH\n",
    "base_path='../../../../' #path of /edmf_estimation\n",
    "sys.path.append(base_path+'edmf_ocean/library/F2PY/')\n",
    "sys.path.append(base_path)\n",
    "from sys import exit\n",
    "import time as TIME\n",
    "import xarray as xr\n",
    "from scipy.interpolate import interp1d\n",
    "from scm_class import SCM\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from case_configs import case_params, default_params\n",
    "from multiprocess import Pool #multiprocessING cannot handle locally defined functions, multiprocess can\n",
    "# from test_version_edmf_ocean import check_edmf_ocean_version\n",
    "# check_edmf_ocean_version()\n",
    "from interpolate_LES_on_SCM_grids import regrid_and_save\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import time as TIME\n",
    "start = TIME.time() #monitor duration of execution \n",
    "import csv\n",
    "\n",
    "# debug=False\n",
    "# if debug:\n",
    "#     # Interactive testing: Set default values for 'metrics'\n",
    "#     waven = '1'\n",
    "#     cas = \"FC500\"\n",
    "# else:\n",
    "#     # If running as a script, capture arguments\n",
    "#     #----- Input arguments\n",
    "#     waven = sys.argv[2]  # First argument   \n",
    "#     cas = sys.argv[1]    # Second argument  \n",
    "waven = '1'\n",
    "# print(\"WAVEN:\", waven)\n",
    "# print(\"cas:\", cas)\n",
    "###########################################\n",
    "# dir = f'../../WORK/BENCHSCMOCEAN/WAVE{waven}/'\n",
    "\n",
    "param_file =f'Par1D_Wave{waven}.asc'\n",
    "# Initialize an empty dictionary\n",
    "data_dict = {}\n",
    "# Open the file and read lines\n",
    "with open(param_file, \"r\") as file:\n",
    "    # Read the first line (header) and strip quotes\n",
    "    header_line = file.readline().strip()\n",
    "    headers = [header.strip('\"') for header in header_line.split()]\n",
    "    \n",
    "    # Store the headers as the first entry in the dictionary\n",
    "    data_dict[\"t_IDs\"] = headers[1:]  # Skip the first header entry, \"t_IDs\"\n",
    "    \n",
    "    # Read the remaining lines for data entries\n",
    "    for line in file:\n",
    "        # Split line into identifier and data values\n",
    "        parts = line.strip().split()\n",
    "        key = parts[0].strip('\"')  # First item is the identifier, without quotes\n",
    "        values = [float(value) for value in parts[1:]]  # Convert remaining values to floats\n",
    "        \n",
    "        # Add to dictionary\n",
    "        data_dict[key] = values\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "# ===================================Load LES========================================\n",
    "cases = ['FC500']\n",
    "# regrid_and_save(cases)\n",
    "TH_les = {}\n",
    "U_les  = {}\n",
    "V_les  = {}\n",
    "time = {}\n",
    "z_r = {}\n",
    "z_w = {}\n",
    "z_r_boolean_filter = {}\n",
    "z_w_boolean_filter = {}\n",
    "dz_TH_les= {}\n",
    "dz_U_les = {}\n",
    "dz_V_les = {}\n",
    "for case in cases:\n",
    "    #------ Opening LES\n",
    "    path= base_path+'data/'+case+'/'\n",
    "    les = xr.open_dataset(path+case+'_interpolated_on_SCM.nc')\n",
    "    print('opening', path+case+'_interpolated_on_SCM.nc')\n",
    "    \n",
    "    \n",
    "    TH_les[case] = les['TH_les'].data.transpose() #transpose to have coordinates as level then time,                                #as in the SCM  \n",
    "    U_les[case]=les['U_les'].data.transpose()\n",
    "    V_les[case]=les['U_les'].data.transpose()\n",
    "\n",
    "    dz_TH_les[case] = les['dz_TH_les'].data.transpose() #transpose to have coordinates as level then time,                                #as in the SCM  \n",
    "    dz_U_les[case]  = les['dz_U_les'].data.transpose()\n",
    "    dz_V_les[case]  = les['dz_U_les'].data.transpose()\n",
    "\n",
    "        #booleans that has been used to filter LES data\n",
    "    z_r_boolean_filter[case] = les['z_r_boolean_filter'].data\n",
    "    z_w_boolean_filter[case] = les['z_w_boolean_filter'].data\n",
    "\n",
    "    time_les = les.time\n",
    "    time[case] = ((time_les - time_les[0]) / np.timedelta64(1, 'h')).data.astype(int) + 1 #numpy array of integer hours, starting at inital time + 1h\n",
    "    \n",
    "    z_r[case] = les['z_r'].data\n",
    "    z_w[case] = les['z_w'].data\n",
    "    \n",
    "#--------------------------------------------\n",
    "\n",
    "\n",
    "def scm_model(X, case):\n",
    "    # ====================================Run the SCM cases=======================================\n",
    "    params = default_params.copy()  # Create a copy of default_params\n",
    "    params.update(case_params[case])  # Update with the specific case hyperparameters in case_params[case]\n",
    "    params_to_estimate = { key: X[i] for i, key in enumerate(data_dict[\"t_IDs\"])} \n",
    "    params_to_estimate['vp_c'] = params_to_estimate['up_c']\n",
    "    params.update(params_to_estimate) # Update with the parameters to estimate\n",
    "    scm = SCM(**params)\n",
    "    scm.run_direct()            # Run the SCM \n",
    "    return scm\n",
    "\n",
    "def compute_metrics(scm,case):\n",
    "    # filter scm outputs\n",
    "    TH_scm = scm.t_history[z_r_boolean_filter[case]]\n",
    "    U_scm  = scm.u_history[z_r_boolean_filter[case]]\n",
    "    V_scm  = scm.v_history[z_r_boolean_filter[case]]\n",
    "    \n",
    "    # compute the space-time L2 average,\n",
    "    # divided by total depth and duration\n",
    "    #trapz is a trapezoidal integral \n",
    "\n",
    "    metric_t = np.trapz( np.trapz( (TH_scm - TH_les[case])**2, z_r[case], axis=0) , time[case]) * 1/(z_r[case][-1] - z_r[case][0]) * 1 / (time[case][-1] - time[case][0]) \n",
    "    metric_u = np.trapz( np.trapz( (U_scm - U_les[case])**2, z_r[case], axis=0) , time[case]) * 1/(z_r[case][-1] - z_r[case][0]) * 1 / (time[case][-1] - time[case][0]) \n",
    "    metric_v = np.trapz( np.trapz( (V_scm - V_les[case])**2, z_r[case], axis=0) , time[case]) * 1/(z_r[case][-1] - z_r[case][0]) * 1 / (time[case][-1] - time[case][0]) \n",
    "\n",
    "    sobolev = False\n",
    "    if sobolev==True:\n",
    "        dz_TH_scm_tempo = np.divide( (scm.t_history[1:] - scm.t_history[:-1]).T ,  scm.z_r[1:]-scm.z_r[:-1]  ).T\n",
    "        dz_U_scm_tempo  = np.divide( (scm.u_history[1:] - scm.u_history[:-1]).T ,  scm.z_r[1:]-scm.z_r[:-1]  ).T\n",
    "        dz_V_scm_tempo  = np.divide( (scm.v_history[1:] - scm.v_history[:-1]).T ,  scm.z_r[1:]-scm.z_r[:-1]  ).T\n",
    "\n",
    "        dz_TH_scm = dz_TH_scm_tempo[z_w_boolean_filter[case]]\n",
    "        dz_U_scm  = dz_U_scm_tempo[z_w_boolean_filter[case]]\n",
    "        dz_V_scm  = dz_V_scm_tempo[z_w_boolean_filter[case]]\n",
    "        #  compute metrics\n",
    "        # (z_w[case] is already filtered)\n",
    "        metric_t_h1 = np.trapz( np.trapz( (dz_TH_scm - dz_TH_les[case])**2, z_w[case], axis=0) , time[case]) * 1/(z_w[case][-1] - z_w[case][0]) * 1 / (time[case][-1] - time[case][0])  \n",
    "\n",
    "        metric_u_h1 = np.trapz( np.trapz( (dz_U_scm - dz_U_les[case])**2, z_w[case], axis=0) , time[case]) * 1/(z_w[case][-1] - z_w[case][0]) * 1 / (time[case][-1] - time[case][0])  \n",
    "        \n",
    "        metric_v_h1 = np.trapz( np.trapz( (dz_V_scm - dz_V_les[case])**2, z_w[case], axis=0) , time[case]) * 1/(z_w[case][-1] - z_w[case][0]) * 1 / (time[case][-1] - time[case][0])  \n",
    "        return metric_t, metric_u, metric_v, metric_t_h1, metric_u_h1, metric_v_h1\n",
    "    return metric_t, metric_u, metric_v \n",
    "\n",
    "# Define the task to parallelize for each run\n",
    "def task(run_id):\n",
    "    if run_id != 't_IDs':\n",
    "        print(f\"Running {case} for {run_id}\")\n",
    "        scm=scm_model(X=data_dict[run_id], case=case)\n",
    "        # metrics.append([run_id, compute_metrics(scm,case)])\n",
    "        return compute_metrics(scm,case)\n",
    "\n",
    "# run in parallel\n",
    "with Pool() as p:\n",
    "    metrics = p.map(task, data_dict.keys())\n",
    "metrics = metrics[1:] #remove 't_IDs' from the list\n",
    "\n",
    "#save to CSV\n",
    "run_id = list(data_dict.keys())[1:]\n",
    "metric_t = [float(metrics[i][0]) for i in range(len(metrics))] #TODO: specify metric to save\n",
    "output_file = \"Metrics.csv\"\n",
    "with open(output_file, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    for rid, val in zip(run_id, metric_t):\n",
    "        writer.writerow([rid, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.31722985e-05, 6.29242945e-05, 7.78650009e-06, 6.81032625e-05,\n",
       "       1.17140214e-04, 6.54486181e-05, 7.19515739e-05, 1.35554670e-04,\n",
       "       1.19692244e-04, 3.70878847e-05])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'t_IDs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_dict\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__delitem__\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt_IDs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m data_dict\n",
      "\u001b[0;31mKeyError\u001b[0m: 't_IDs'"
     ]
    }
   ],
   "source": [
    "data_dict.__delitem__('t_IDs')\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SCM-1-001',\n",
       " 'SCM-1-002',\n",
       " 'SCM-1-003',\n",
       " 'SCM-1-004',\n",
       " 'SCM-1-005',\n",
       " 'SCM-1-006',\n",
       " 'SCM-1-007',\n",
       " 'SCM-1-008',\n",
       " 'SCM-1-009',\n",
       " 'SCM-1-010']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = list(data_dict.keys())[1:]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7.3172298485494e-05, 3.4161232221017545e-09, 3.4161232221017545e-09),\n",
       " (6.292429453133026e-05, 3.4161232221017545e-09, 3.4161232221017545e-09),\n",
       " (7.786500086039598e-06, 3.4161232221017545e-09, 3.4161232221017545e-09),\n",
       " (6.810326253621383e-05, 3.4161232221017545e-09, 3.4161232221017545e-09),\n",
       " (0.00011714021440020448, 3.4161232221017545e-09, 3.4161232221017545e-09),\n",
       " (6.544861811234289e-05, 3.4161232221017545e-09, 3.4161232221017545e-09),\n",
       " (7.195157389215376e-05, 3.4161232221017545e-09, 3.4161232221017545e-09),\n",
       " (0.00013555466959539814, 3.4161232221017545e-09, 3.4161232221017545e-09),\n",
       " (0.00011969224433719221, 3.4161232221017545e-09, 3.4161232221017545e-09),\n",
       " (3.70878847485327e-05, 3.4161232221017545e-09, 3.4161232221017545e-09)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.3172298485494e-05,\n",
       " 6.292429453133026e-05,\n",
       " 7.786500086039598e-06,\n",
       " 6.810326253621383e-05,\n",
       " 0.00011714021440020448,\n",
       " 6.544861811234289e-05,\n",
       " 7.195157389215376e-05,\n",
       " 0.00013555466959539814,\n",
       " 0.00011969224433719221,\n",
       " 3.70878847485327e-05]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_t = [float(metrics[i][0]) for i in range(len(metrics))]\n",
    "metric_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "output_file = \"output.csv\"\n",
    "with open(output_file, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    # writer.writerow([\"Run_ID\", \"Value\"])  # Add headers if needed\n",
    "    for rid, val in zip(run_id, metric_t):\n",
    "        writer.writerow([rid, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running FC500 for SCM-1-001\n",
      "Running FC500 for SCM-1-002\n",
      "Running FC500 for SCM-1-003\n",
      "Running FC500 for SCM-1-004\n",
      "Running FC500 for SCM-1-005\n",
      "Running FC500 for SCM-1-006\n",
      "Running FC500 for SCM-1-007\n",
      "Running FC500 for SCM-1-008\n",
      "Running FC500 for SCM-1-009\n",
      "Running FC500 for SCM-1-010\n"
     ]
    }
   ],
   "source": [
    "for key in data_dict.keys():\n",
    "    task(key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
